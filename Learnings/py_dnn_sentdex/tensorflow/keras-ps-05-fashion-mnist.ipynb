{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch_size = 128\n",
    "epochs = 24\n",
    "\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "print(x_train.shape)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, train_size=50000, test_size=10000)\n",
    "print(x_train.shape)\n",
    "print(x_validation.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    x_validation = x_validation.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    x_validation = x_validation.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1) train samples\n",
      "(10000, 28, 28, 1) test samples\n",
      "(10000, 28, 28, 1) validation samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_validation = x_validation.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_validation /= 255\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')\n",
    "print(x_validation.shape, 'validation samples')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_validation = keras.utils.to_categorical(y_validation, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same',\n",
    "                     #kernel_regularizer=keras.regularizers.l1(l=0.00001),\n",
    "                     input_shape=input_shape\n",
    "                    ))\n",
    "    #model.add(MaxPooling2D( pool_size=(2, 2) ))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same',\n",
    "                     #kernel_regularizer=keras.regularizers.l1(l=0.00001)\n",
    "                    ))\n",
    "    model.add(MaxPooling2D( pool_size=(2, 2) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128,\n",
    "                    activation='relu',\n",
    "                   # kernel_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "                    kernel_regularizer=keras.regularizers.l1(l=0.00001)\n",
    "                   )\n",
    "             )\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    #kernel_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "                    kernel_regularizer=keras.regularizers.l1(l=0.00001)\n",
    "                   )\n",
    "             )\n",
    "    \n",
    "    optimizer = Adam()\n",
    "    %time model.compile(loss=keras.losses.categorical_crossentropy,optimizer=optimizer,metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 ms, sys: 0 ns, total: 23.3 ms\n",
      "Wall time: 23.3 ms\n"
     ]
    }
   ],
   "source": [
    "model = create_conv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,625,866\n",
      "Trainable params: 1,625,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_acc\", mode=max, verbose=1, patience=3)\n",
    "\n",
    "filepath=\"keras-fmnist-dnn-tuto-{epoch:02d}-{val_acc:.5f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,save_weights_only=False, mode='max')\n",
    "\n",
    "my_callbacks = [early_stopping, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/24\n",
      "50000/50000 [==============================] - 178s 4ms/step - loss: 0.6730 - acc: 0.8132 - val_loss: 0.4780 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88300, saving model to keras-fmnist-dnn-tuto-01-0.88300.hdf5\n",
      "Epoch 2/24\n",
      "50000/50000 [==============================] - 176s 4ms/step - loss: 0.4919 - acc: 0.8767 - val_loss: 0.4395 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88300 to 0.89280, saving model to keras-fmnist-dnn-tuto-02-0.89280.hdf5\n",
      "Epoch 3/24\n",
      "50000/50000 [==============================] - 174s 3ms/step - loss: 0.4480 - acc: 0.8886 - val_loss: 0.4248 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89280 to 0.90360, saving model to keras-fmnist-dnn-tuto-03-0.90360.hdf5\n",
      "Epoch 4/24\n",
      "50000/50000 [==============================] - 175s 3ms/step - loss: 0.4217 - acc: 0.8997 - val_loss: 0.4080 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90360 to 0.90480, saving model to keras-fmnist-dnn-tuto-04-0.90480.hdf5\n",
      "Epoch 5/24\n",
      "50000/50000 [==============================] - 174s 3ms/step - loss: 0.4067 - acc: 0.9059 - val_loss: 0.4071 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90480 to 0.90690, saving model to keras-fmnist-dnn-tuto-05-0.90690.hdf5\n",
      "Epoch 6/24\n",
      "50000/50000 [==============================] - 174s 3ms/step - loss: 0.3937 - acc: 0.9104 - val_loss: 0.4095 - val_acc: 0.9121\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90690 to 0.91210, saving model to keras-fmnist-dnn-tuto-06-0.91210.hdf5\n",
      "Epoch 7/24\n",
      "50000/50000 [==============================] - 174s 3ms/step - loss: 0.3806 - acc: 0.9173 - val_loss: 0.4005 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91210\n",
      "Epoch 8/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3728 - acc: 0.9202 - val_loss: 0.3972 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91210 to 0.91920, saving model to keras-fmnist-dnn-tuto-08-0.91920.hdf5\n",
      "Epoch 9/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3641 - acc: 0.9244 - val_loss: 0.3971 - val_acc: 0.9184\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91920\n",
      "Epoch 10/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3617 - acc: 0.9265 - val_loss: 0.3918 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91920\n",
      "Epoch 11/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3549 - acc: 0.9300 - val_loss: 0.3966 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.91920 to 0.92120, saving model to keras-fmnist-dnn-tuto-11-0.92120.hdf5\n",
      "Epoch 12/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3522 - acc: 0.9305 - val_loss: 0.4053 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92120\n",
      "Epoch 13/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3480 - acc: 0.9346 - val_loss: 0.4090 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.92120 to 0.92130, saving model to keras-fmnist-dnn-tuto-13-0.92130.hdf5\n",
      "Epoch 14/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3439 - acc: 0.9366 - val_loss: 0.3976 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.92130 to 0.92310, saving model to keras-fmnist-dnn-tuto-14-0.92310.hdf5\n",
      "Epoch 15/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3406 - acc: 0.9389 - val_loss: 0.4071 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.92310 to 0.92350, saving model to keras-fmnist-dnn-tuto-15-0.92350.hdf5\n",
      "Epoch 16/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3357 - acc: 0.9404 - val_loss: 0.4005 - val_acc: 0.9232\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92350\n",
      "Epoch 17/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3323 - acc: 0.9427 - val_loss: 0.4136 - val_acc: 0.9246\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.92350 to 0.92460, saving model to keras-fmnist-dnn-tuto-17-0.92460.hdf5\n",
      "Epoch 18/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3360 - acc: 0.9424 - val_loss: 0.4106 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.92460 to 0.92510, saving model to keras-fmnist-dnn-tuto-18-0.92510.hdf5\n",
      "Epoch 19/24\n",
      "50000/50000 [==============================] - 173s 3ms/step - loss: 0.3331 - acc: 0.9444 - val_loss: 0.4094 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.92510 to 0.92590, saving model to keras-fmnist-dnn-tuto-19-0.92590.hdf5\n",
      "Epoch 20/24\n",
      "49920/50000 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.9454"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size=batch_size, callbacks=my_callbacks, epochs=epochs, verbose=1, \n",
    "              validation_data=(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"kera-fmnist-conv.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.ion()\n",
    "plt.axis('equal')\n",
    "\n",
    "import numpy as np\n",
    "epoch_list = list(range(1, len(hist.history['acc']) + 1))\n",
    "plt.plot(epoch_list, hist.history['acc'], epoch_list, hist.history['val_acc'])\n",
    "plt.legend('Training Accuracy', 'Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
